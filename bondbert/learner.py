"Utilities to manage individual learners of the ensemble"

import torch
import numpy as np
from datasets import DatasetDict
from typing import List, Optional
from .data import TokenizeHandler
from torch.utils.data import DataLoader
from transformers import BertForTokenClassification
from transformers.tokenization_utils_base import BatchEncoding

class Learner:
    """
    Class for interfacing with individual sublearners within the ensemble
    Params:
        name (str): Hugging Face model alias for learner
        model (transformers.BertForTokenClassification): Model object for learner
        tokenize_handler (bondbert.TokenizeHandler): TokenizeHandler object for learner's tokenization scheme
        device (str): Device for hosting model
        dataloader (torch.DataLoader): DataLoader object for storing tokenized dataset
    """
    def __init__(self, 
                 name: str,
                 model: BertForTokenClassification,
                 tokenize_handler: TokenizeHandler,
                 device: str,
                 dataloader: DataLoader = None):
        self.name = name
        
        self.model = model.to(device)
        self.model.eval()
        
        self.tokenize_handler = tokenize_handler
        self.dataloader = dataloader
        self.device = device
        
    def __repr__(self):
        return f"Learner({self.name})"
        
    def init_dataloader(self,
                        dataset: DatasetDict,
                        batch_size: int):
        """
        Initialize a dataloader for `dataset` using the tokenization scheme of the learner
        Params:
            dataset (datasets.DatasetDict): Dataset to be loaded 
            batch_size (int): Batch size to use in loading data
        """
        self.dataloader = self.tokenize_handler.make_dataloader(dataset, batch_size)
        
    def get_tokens(self,
                   batch: BatchEncoding):
        """
        Retrieve the tokens generated by the tokenization scheme of the learner for `batch`
        Params:
            batch (transformers.BatchEncoding): Current data batch
        Return:
            tokens (np.array): Tokenization of `batch` under the learner's tokenization scheme
        """
        id_to_token = {v: k for k, v in self.tokenize_handler.get_vocab()}
        input_ids = batch["input_ids"]
        if torch.is_tensor(input_ids):
            input_ids = input_ids.clone().cpu()
        tokens = np.vectorize(id_to_token.get)(input_ids.numpy())
        return tokens
        
    def get_output(self, 
                   batch: BatchEncoding):
        """
        Generates a LearnerOutput object containing logit predictions and corresponding tokens for entries in `batch`
        Params:
            batch (transformers.BatchEncoding): Current data batch
        Return:
            output (bondbert.LearnerOutput): LearnerOutput object containing logit predictions and corresponding tokens
        """
        # If training data contains ground truth labels, store these in the output for performance metric calculation
        if "labels" in batch:
            labels = batch["labels"]
        else:
            labels = None
        tokens = self.get_tokens(batch)
        prediction = self.model(**batch)
        logits = prediction.logits
        output = LearnerOutput(self.name, tokens, logits, labels)
        return output
        
        
class LearnerOutput:
    """
    Class for storing tokens, logits, and entity labels for learners of the ensemble as input to alignment algorithm
    Params:
        name (str): Hugging face alias for learner
        tokens (np.array): Tokens of current batch
        logits (torch.Tensor): Logit predictions for each possible entity tag by learner on the current batch
        labels (list): Ground truth entity tag labels
    """
    def __init__(self, 
                 name: str, 
                 tokens: np.array, 
                 logits: torch.Tensor, 
                 labels: Optional[List[str]] = None):
        self.name = name
        self.tokens = tokens
        self.logits = logits
        self.labels = labels
        
    def __repr__(self):
        return f"LearnerOutput({self.name})"